# -*- coding: utf-8 -*-
"""L1L2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1giWqUZCQD4cg_Ahc-ueMtsMkuHIWWPqQ

# Regresja liniowa, Ridge i Lasso

## a) Przykład równania regresji i predykcji

Rozważmy regresję liniową z dwiema zmiennymi objaśniającymi:

$$
\hat y = \beta_0 + \beta_1 x_1 + \beta_2 x_2
$$

Przykładowo (czysto ilustracyjnie), jeśli zmienne są funkcjami cosinus:

$$
\hat y = \beta_0 + \beta_1 \cos(x_1) + \beta_2 \cos(x_2)
$$

Dla przykładowych współczynników:
- $$\beta_0 = 1.0$$
- $$\beta_1 = 0.5$$
- $$\beta_2 = -0.3$$

oraz danych:
- $$x_1 = 0$$
- $$x_2 = \pi / 2$$

predykcja $$\hat y$$ jest liczona przez bezpośrednie podstawienie do wzoru.

---

## b) Funkcja straty – wersja podstawowa

W regresji liniowej chcemy, aby predykcja $$\hat y$$ była jak najbliżej wartości rzeczywistej $$y$$.

Najprostsza intuicyjna strata to różnica:

$$
(y - \hat y)
$$

W praktyce różnicę tę podnosi się do kwadratu i sumuje po wszystkich obserwacjach.

Ważne jest, aby pamiętać, że:

$$
\hat y = \beta_0 + \beta_1 x_1 + \beta_2 x_2
$$

---

## c) Funkcja straty Ridge (L2)

W regresji Ridge do klasycznej straty dodajemy karę za duże wartości współczynników:

$$
RSS_{L2} =
\sum_{i=1}^{n} (y_i - \hat y_i)^2
+
\lambda \sum_{j=1}^{p} \beta_j^2
$$

Kara L2 powoduje, że:
- duże współczynniki są silnie tłumione,
- bardzo małe współczynniki (dużo mniejsze od 1) są karane słabo.

---

## d) Funkcja straty Lasso (L1)

W regresji Lasso stosuje się inną postać kary:

$$
RSS_{L1} =
\sum_{i=1}^{n} (y_i - \hat y_i)^2
+
\lambda \sum_{j=1}^{p} |\beta_j|
$$

Kara L1 (wartość bezwzględna):
- silnie karze nawet bardzo małe w

**W skrócie:** Lasso sprzyja selekcji zmiennych, a Ridge stabilizacji współczynników.


**W skrócie:** Lasso sprzyja selekcji zmiennych, a Ridge stabilizacji współczynników.
**W skrócie:**  
Lasso sprzyja selekcji zmiennych, a Ridge stabilizacji współczynników.

## e) Porównanie Ridge i Lasso – intuicja

- **Lasso** mocno karze małe współczynniki kierunkowe, co sprzyja ich wyzerowaniu (selekcja zmiennych).
- **Ridge** jest łagodny dla bardzo małych współczynników (≪ 1), ale coraz silniej karze współczynniki duże.
- Różnica ta wynika bezpośrednio z postaci kary: $$\beta^2$$ (Ridge) vs $$|\beta|$$ (Lasso).

**W skrócie:** Lasso sprzyja selekcji zmiennych, a Ridge stabilizacji współczynników.
"""

from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from scipy.stats import iqr
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import RandomizedSearchCV
from sklearn.inspection import permutation_importance

# =========================
# Core libraries
# =========================
import numpy as np
import pandas as pd

# =========================
# Visualization (optional but common)
# =========================
import matplotlib.pyplot as plt
import seaborn as sns

# =========================
# Scikit-learn: data & utilities
# =========================
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# =========================
# Scikit-learn: regression models
# =========================
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# =========================

# =========================


# =========================
# Scikit-learn: metrics
# =========================
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# =========================
# Load California Housing dataset
# =========================
california = fetch_california_housing(as_frame=True)

X = california.data
y = california.target

df = X.copy()
df["target"] = y

# Dataset description (string)
dataset_description = california.DESCR

# Quick sanity check
df.head()

print(dataset_description)

df.info()

for c in df.columns :
    print(c, '\n' * 2, df[c].sample(n = 10), '\n')

statystyki_opisowe = df.describe().round(2)
statystyki_opisowe

statystyki_opisowe.loc[['mean', '50%', 'min', 'max'], : ]

df[df.duplicated()]

"""## Badamy rozkład zmiennej którą przewidujemy"""

df.target.sum()

df.target.plot.hist()
plt.title('Rozkład zmiennej objaśnianej - ceny domu')
plt.ylabel('Liczba obserwacji')
plt.xlabel('Przedział ceny domu')
plt.show()

"""## Naiwna, baseline predykcja

Kiedy dostaniemy wynik modelu, musimy to z czymś porównać. Na pewno chcemy model, który jest lepszy od mówienia zawsze, że cena domu będzie taka, jak średnia cen domu w przeszłości.
"""

df['target'].mean()

naiwna_predykcja_srednia = df.target.median()
naiwna_predykcja_srednia

range(3)

for i in range(3) :
    print( i )

liczby = [ i for i in range(3) ]
liczby

for i in range(len(liczby)) :
    print( 'hi' )

naiwne_predykcje = [ naiwna_predykcja_srednia for i in range(len(df)) ]
naiwne_predykcje[ : 10]

"""## Oczekujemy, że nasz model będzie miał lepszą wartość metryki"""

mean_absolute_error( df.target, naiwne_predykcje)

# =========================
# Train-test split (default setup)
# =========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

y_train.sum() + y_test.sum()

trainset.MedHouseVal.sum() + testset.MedHouseVal.sum()

X_train.head(2)

trainset = pd.concat( [X_train, y_train], axis = 1)
testset = pd.concat( [X_test, y_test], axis = 1)

trainset.head()

trainset.corr().round(2)

for c in trainset.columns :
    if c != 'MedHouseVal' :
        print()
        plt.scatter( trainset[c], trainset['MedHouseVal'] )
        plt.title("MedHouseVal w zależności od {}".format(c))
        plt.ylabel('Cena domu')
        plt.xlabel(c)
        plt.show()
        print()

malo_pokoi = trainset[ trainset['AveRooms'] < 10 ]
malo_pokoi.shape

plt.scatter( malo_pokoi['AveRooms'], malo_pokoi['MedHouseVal'] )
plt.ylabel('MedHouseVal')
plt.xlabel('AveRooms')
plt.title('Zależność ceny domu od liczby pokoi dla liczby pokoi mniejszej od 10')
plt.show()

"""## Analiza obserwacji odstajacych numerycznie od pozostalych"""

for c in trainset.columns :
    print()
    sns.boxplot(y = c, data = trainset)
    plt.title("Percentyle i obserwacje odstające zmiennej {}".format(c))
    plt.ylabel(c)
    plt.show()
    print()

"""## Wyliczamy progi liczb do wykluczenia z danych do modelowania"""

progi_duzych_liczby_wg_kolumn = {}
progi_malych_liczby_wg_kolumn = {}

for c in trainset.columns :
    poltora_iqr = 1.5 * iqr( trainset[c] )
    # czyli dolna krawedz pudelka na boxplot (wyrkes ramka-wasy)
    dolny_kwartyl = np.percentile( trainset[c], 0.25 )

    # czyli gorna krawedz pudelka na boxplot (wyrkes ramka-wasy)
    gorny_kwartyl = np.percentile( trainset[c], 0.75 )

    # liczby ktore sa za duze
    gorny_prog = gorny_kwartyl + poltora_iqr

    # liczby ktore sa za male
    dolny_prog = dolny_kwartyl - poltora_iqr

    progi_duzych_liczby_wg_kolumn[c] = gorny_prog

    progi_malych_liczby_wg_kolumn[c] = dolny_prog



progi_duzych_liczby_wg_kolumn

for c in trainset.columns :
    # usuwamy za duze liczby ze zbioru treningowego
    trainset = trainset[ trainset[c] < progi_duzych_liczby_wg_kolumn[c]  ]

    # usuwamy za duze liczby ze zbioru testowego wg tych samych progow
    testset = testset[ testset[c] < progi_duzych_liczby_wg_kolumn[c]  ]

    # usuwamy za male liczby ze zbioru treningowego
    trainset = trainset[ trainset[c] > progi_malych_liczby_wg_kolumn[c]  ]

    # usuwamy za male liczby ze zbioru testowego wg tych samych progow
    testset = testset[ testset[c] > progi_malych_liczby_wg_kolumn[c]  ]

for c in trainset.columns :
    print()
    sns.boxplot(y = c, data = trainset)
    plt.title("Percentyle i obserwacje odstające zmiennej {} po usunięciu obserwacji ekstremalnych".format(c))
    plt.ylabel(c)
    plt.show()
    print()

trainset.corr().round(2)



trainset.head()

trainset['MedIncInterval'] = pd.qcut( trainset['MedInc'], q = 4).astype(str)
trainset.head()

trainset.groupby('MedIncInterval')['MedHouseVal'].mean().plot.barh()
plt.title('Ceny domów w zależności od przedziałów dochodów lokalnej ludności', pad = 15, fontsize = 14)
plt.ylabel('MedIncInterval', labelpad = 15, fontsize = 13)
plt.xlabel('Cena domu', labelpad = 15, fontsize = 13)
plt.show()

trainset['AveRoomsInterval'] = pd.qcut( trainset['AveRooms'], q = 4).astype(str)


trainset.groupby('AveRoomsInterval')['MedHouseVal'].mean().plot.barh()
plt.title('Ceny domów w zależności od przedziałów liczby pokoi', pad = 15, fontsize = 14)
plt.ylabel('Licba pokoi', labelpad = 15, fontsize = 13)
plt.xlabel('Cena domu', labelpad = 15, fontsize = 13)
plt.show()

['MedInc','HouseAge', 'AveRooms', 'Latitude'] + ['MedHouseVal']

[1, 2] + [1, 1] # listy pythonowe wbudowane

np.array([1, 2]) + np.array([1, 1]) # tablice numpy

# na podstawie korelacji i wykresow
zmienne_do_modelu = ['MedInc','HouseAge', 'AveRooms', 'Latitude']

trainset_selected = trainset[zmienne_do_modelu + ['MedHouseVal']]
testset_selected = testset[zmienne_do_modelu + ['MedHouseVal']]

scaler = StandardScaler()
trainset_selected_scaled = pd.DataFrame( scaler.fit_transform(trainset_selected), columns = trainset_selected.columns )

# na testowym transform a nie fit transform!
testset_selected_scaled = pd.DataFrame( scaler.transform(testset_selected), columns = testset_selected.columns )

trainset_selected_scaled.head()

trainset_selected_scaled.describe().round(2)

testset_selected.head(2)

X_train = trainset_selected_scaled.drop('MedHouseVal', axis = 1)
y_train = trainset_selected['MedHouseVal']

X_test = testset_selected_scaled.drop('MedHouseVal', axis = 1)
y_test = testset_selected_scaled['MedHouseVal']

"""## Baseline model"""

ridge = Ridge()
ridge.fit(X_train, y_train)
train_ridge_preds = ridge.predict(X_train)
test_ridge_preds = ridge.predict(X_test)

err_train = mean_absolute_error(y_train, train_ridge_preds)
err_test = mean_absolute_error(y_test, test_ridge_preds)

print("Średni błąd bezwzględny na zbiorze treningowym jest {} a na testowym {}".format(err_train, err_test))

def perform_randomized_grid_search(X_train, y_train, algorithm, param_distributions, n_iter=100, cv=5, scoring='accuracy',\
                                   random_state=42, debug=False, verbose = 0):
    """
    Perform a randomized grid search to find the best hyperparameters for a given algorithm.

    Parameters:
    algorithm (estimator): The machine learning algorithm to optimize.
    param_distributions (dict): The parameter distributions to sample from during the search.
    n_iter (int): Number of parameter settings that are sampled. Defaults to 100.
    cv (int): Number of cross-validation folds. Defaults to 5.
    scoring (str): The metric to optimize. Defaults to 'accuracy'.
    random_state (int): Random seed for reproducibility. Defaults to 42.

    Returns:
    best_estimator (estimator): The best estimator found by the search.
    best_score (float): The best score achieved by the best estimator.
    best_params (dict): The best hyperparameters found by the search.

    Example:
    param_distributions = {
     'n_estimators': [100, 200, 300, 400, 500],
     'max_features': ['auto', 'sqrt', 'log2'],
     'max_depth': [None, 10, 20, 30, 40, 50],
     'min_samples_split': [2, 5, 10],
     'min_samples_leaf': [1, 2, 4]
        }

    best_estimator, best_score, best_params = perform_randomized_grid_search(X_train, y_train, RandomForestClassifier(), param_distributions)

    print("Best Estimator:", best_estimator)
    print("Best Score:", best_score)
    print("Best Parameters:", best_params)

    Best Estimator: RandomForestClassifier(max_depth=40, max_features='log2', n_estimators=200)
    Best Score: 0.9926412487912696
    Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 40}
    """
    # Initialize the RandomizedSearchCV object
    randomized_search = RandomizedSearchCV(
        estimator=algorithm,
        param_distributions=param_distributions,
        n_iter=n_iter,
        cv=cv,
        scoring=scoring,
        random_state=random_state,
        n_jobs=-1,
        verbose=verbose

    )

    # Fit the randomized search to the data
    randomized_search.fit(X_train, y_train)

    # Get the best estimator, score, and parameters
    best_estimator = randomized_search.best_estimator_
    best_score = randomized_search.best_score_
    best_params = randomized_search.best_params_

    if debug :
        debug_results = pd.DataFrame(randomized_search.cv_results_)

        return debug_results

    return best_estimator, best_score, best_params

rf_grid = {
     'n_estimators': [100, 200, 300, 400],
     'max_features': ['auto', 'sqrt', 'log2'],
     'max_depth': [None, 3, 5, 10, 20, 30 ],
     'min_samples_split': [2, 5, 10, 20, 40],
     'min_samples_leaf': [2, 4, 16, 64]
 }

ridge_grid = { 'alpha' :  list(np.linspace(0.01, 2, 200)) }

import sklearn
sklearn.metrics.SCORERS.keys()

ridge_estimator, ridge_score, ridge_params = perform_randomized_grid_search(X_train, y_train, Ridge(), ridge_grid, scoring = "neg_mean_absolute_error", n_iter = 75)

print("Best Estimator:", ridge_estimator, "\n")
print("Best Score:", ridge_score, "\n")
print("Best Parameters:", ridge_params, "\n")

rf_estimator, rf_score, rf_params = perform_randomized_grid_search(X_train, y_train, RandomForestRegressor(random_state=123), rf_grid, scoring = "neg_mean_absolute_error", n_iter = 40)

print("Best Estimator:", rf_estimator, "\n")
print("Best Score:", rf_score, "\n")
print("Best Parameters:", rf_params, "\n")

gb_grid = {
     'n_estimators': [100, 200, 300, 400],
     'max_features': ['auto', 'sqrt', 'log2'],
     'max_depth': [2, 3, 5 ],
     'min_samples_split': [10, 15, 20, 25, 40],
     'min_samples_leaf': [16, 32, 64],
    'learning_rate' : [0.05, 0.1, 0.15]
 }

gb_estimator, gb_score, gb_params = perform_randomized_grid_search(X_train, y_train, GradientBoostingRegressor(random_state=123), gb_grid, scoring = "neg_mean_absolute_error", n_iter = 75)

print("Best Estimator:", gb_estimator, "\n")
print("Best Score:", gb_score, "\n")
print("Best Parameters:", gb_params, "\n")

final_preds =  gb_estimator.predict(X_test)
final_preds_train = gb_estimator.predict(X_train)

err_train_gb = mean_absolute_error(y_train, final_preds_train)
err_test_gb = mean_absolute_error(y_test, final_preds)


print("Średni błąd bezwzględny ztuningowanego GradientBoostingRegressor na zbiorze treningowym jest {} a na testowym {}"\
      .format(err_train_gb, err_test_gb))

def feature_importance( model, index, target_variable, perm_imp = False, X_val = None, y_val = None, fig_size_tup=(10, 6), n=10,
                       full_table=False, ascending=False, random_state=0, n_repeats=30):
    """
    Returns the feature importances in the form of a table or a grouped bar chart.

    Parameters
    ----------
    model : fitted sklearn tree-based model such as Decision Tree or Random Forest.
    index : list of strings
        The features the model was trained with.
    target_variable : str
        The name of the target variable to be included in the title of the plot.
        Relevant only if full_table = False.
    perm_imp : bool
        Whether to compute permutation importances.
        Defaults to False.
    X_val : pd.DataFrame
        Validation / test features.
        Defaults to None.
        Relevant only if perm_imp = True.
    y_val : pd.Series or np.array
        Validation / test target values.
        Defaults to None.
        Relevant only if perm_imp = True.
    fig_size_tup : tuple
        The size of the plot. Relevant only if full_table = False.
        Defaults to (10, 6).
    n : int
        Number of variables to display on feature importances plot.
        Relevant only if full_table = False.
        Defaults to 10.
    full_table : bool
        Whether to return a full table of importances or plot a chart.
        Defaults to False.
    ascending : bool
        Sort order of feature importances.
        Defaults to False.
    random_state : int
        Random state for reproducibility.
        Defaults to 0.
    n_repeats : int
        Number of repeats for permutation importance.
        Defaults to 30.

    Returns
    -------
    None if full_table = False (Displays the plot).
    pandas.DataFrame if full_table = True (Feature importances table).
    """

    # Compute impurity-based importances
    try:
        impurity_importances = pd.DataFrame(model.feature_importances_,
                                            index=index, columns=['Impurity Importance'])
    except AttributeError:
        print("Skipping impurity importance as the provided model does not have the 'feature_importances_' attribute .")
        impurity_importances = None

    if perm_imp :
        # Compute permutation importances
        perm_imp_result = permutation_importance(model, X_val, y_val, n_repeats=n_repeats, random_state=random_state)
        perm_importances = pd.DataFrame(perm_imp_result['importances_mean'], index=index, columns=['Permutation Importance'])

        if impurity_importances is None:
            feature_importances =  perm_importances.sort_values('Permutation Importance', ascending=ascending)
        else :
            # Combine both importance metrics
            feature_importances = pd.concat([impurity_importances, perm_importances], axis=1)
            feature_importances = feature_importances\
                .sort_values('Permutation Importance', ascending=ascending) [ [ 'Permutation Importance', 'Impurity Importance' ] ]
    else :
        feature_importances = impurity_importances.sort_values('Impurity Importance', ascending=ascending)

    if full_table:
        return feature_importances

    # Prepare for plotting
    top_features = feature_importances.head(n)

    color_mapping = {'Impurity Importance': 'lightcoral', 'Permutation Importance': 'red'}
    colors = [color_mapping[col] for col in top_features.columns]

    #[ 'lightcoral', 'red' ]
    # Plot grouped bar chart
    ax = top_features.plot( kind='bar', figsize=fig_size_tup, rot = 70, color = colors  )
    ax.set_title( f'Importances of different variables affecting {target_variable}', fontsize=15, pad=15 )
    ax.set_ylabel( "Importance", fontsize=13, labelpad=14 )
    ax.set_xlabel( "Feature", fontsize=13, labelpad=14 )
    ax.legend( title="Importance Type" )
    ax.grid( axis="y" )

    return None

feature_importance( gb_estimator, X_train.columns, '\nhouse prices in Gradient Boosting Regressor', perm_imp = True, X_val = X_test, y_val = y_test, n = 5 )

feature_importance( ridge_estimator, X_train.columns, '\nhouse prices in Ridge Regressor', perm_imp = True, X_val = X_test, y_val = y_test, n = 5 )

