# -*- coding: utf-8 -*-
"""predicting_species.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gqZbQ3-fU2L5w_LPV6aaiE4UGLfIvQpG

Problem Statement:

Scientists have determined that a known species of bird should be divided into 3 distinct and separate species. These species are endemic to a particular region of the country and their populations must be tracked and estimated with as much precision as possible. As such, a non-profit conservation society has taken up the task. They need to be able to log which species they have encountered based on the characteristics that their field officers observe in the wild.

Using certain genetic traits and location data, can you predict the species of bird that has been observed?

This is a beginner-level practice competition and your goal is to predict the bird species (A, B, or C) based on attributes or location.

## Import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd

# plotting
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
matplotlib.rcParams['figure.dpi'] = 100
sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.set(style="whitegrid")
# %matplotlib inline

pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

# ml
from sklearn.metrics import ConfusionMatrixDisplay, classification_report
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score
from sklearn.preprocessing import OneHotEncoder
import numpy as np
import ppscore as pps
from lazypredict.Supervised import LazyClassifier
from sklearn.ensemble import RandomForestClassifier

"""## Load data"""

train = pd.read_csv("training_set.csv")
labels = pd.read_csv("training_target.csv")

# join target variable to training set
train = train.merge(labels, on="ID")

test = pd.read_csv("test_set.csv")

train.head()

train.info()

train.isna().sum().sort_values(ascending = False)

train.shape

train.shape[0]

train.isna().sum().sort_values(ascending = False).div(train.shape[0]).round(2)

for c in train.columns :
    print(f'Wartości kolumny {c}', '\n' * 2, train[c].sample(n = 10), '\n' )

train[ train.duplicated() ]

train.duplicated().sum()

print("Przed usunięciem duplikatów mamy {} wierszy".format(train.shape[0]))

train = train[ ~ train.duplicated() ]

print("Po usunięciu duplikatów mamy {} wierszy".format(train.shape[0]))

statystyki = train.describe().round(2)
statystyki.head(2)

statystyki.loc[ ['mean', '50%', 'min', 'max'], 'bill_depth' : 'sex'  ]

train.species.value_counts(normalize = True, dropna = False).plot.bar()
plt.title('Rozkład zmiennej objaśnianej (y) - gatunku ptaka')
plt.ylabel('Odsetek')
plt.xlabel('Gatunek')
plt.show()

train.location.unique()

train.head(2)

train.ID.nunique() == train.shape[0]

train = train.set_index('ID')
train.head(2)

435*0.7

y = train['species']
X = train.drop('species', axis = 1)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)

X_train.head()

X_train.isna().sum().sort_values(ascending = False).div(X_train.shape[0]).round(2)

trainset = pd.concat( [ X_train, y_train ], axis = 1 )
testset = pd.concat( [ X_test, y_test ], axis = 1 )

trainset.head()

sns.kdeplot(x = 'bill_depth', data = trainset, hue = 'species', common_norm = False)
plt.title('Rozkład głębokości dzioba dla poszczególnych gatunków')
plt.xlabel('Głębokość dzioba')
plt.show()



trainset['bill_length'].isna()

bill_length_jest = trainset [ ~ trainset['bill_length'].isna() ]
bill_length_jest.head()

bill_length_nie_ma = trainset [ trainset['bill_length'].isna() ]
bill_length_nie_ma.head()

trainset[ 'bill_length_nan'  ] = trainset['bill_length'].isna().astype(int)
trainset.head(3)

testset[ 'bill_length_nan'  ] = testset['bill_length'].isna().astype(int)

trainset.groupby('bill_length_nan')['species'].value_counts(normalize = True).unstack().plot.bar()
plt.title('Rozkład gatunku w zależności czy długość dzioba jest NaN')
plt.xlabel('Czy jest NaN?')
plt.ylabel('Odsetek ptaków')
plt.show()

encoder = SimpleImputer() # domyslnie uzywa sredniej
cols_avg = ['bill_length', 'wing_length']
trainset[cols_avg] = encoder.fit_transform(trainset[cols_avg])

testset[cols_avg] = encoder.transform(testset[cols_avg])

trainset.isna().sum().sort_values(ascending = False)

trainset.shape

one_hot = OneHotEncoder(sparse = False)
trainset['location'] = one_hot.fit_transform(pd.DataFrame(trainset['location']).values.reshape(-1, 1))
testset['location'] = one_hot.transform(pd.DataFrame(testset['location']).values.reshape(-1, 1))

trainset.shape

trainset.head(2)

trainset.isna().sum().sort_values(ascending = False) # zniknely braki po zastosowaniu OHE

trainset.location.unique() # gdzie trzecia lokacja?

ohe_test = OneHotEncoder(sparse = False)
ohe_test.fit_transform( np.array( ['a', 'b', 'c'] ).reshape(-1, 1) )

encoder = SimpleImputer(strategy = 'most_frequent')
cols_mode = ['sex']
trainset[cols_mode] = encoder.fit_transform(trainset[cols_mode])

testset[cols_mode] = encoder.transform(testset[cols_mode])

trainset.isna().sum().sum()

trainset['location'].head()

trainset.head(2)

x = 3
y = 5

print(x, y)

x, y = 7, 8

print(x, y)

X_train, y_train = trainset.drop('species', axis = 1), trainset['species']
X_test, y_test = testset.drop('species', axis = 1), testset['species']

X_test.isna().sum()

X_test['bill_depth'] = X_test['bill_depth'].fillna(X_test['bill_depth'].mean())

X_train.head()

pps.predictors(trainset, y = 'species')

"""dt = DecisionTreeClassifier()
dt.fit(bill_length, y)

dt = DecisionTreeClassifier()
dt.fit(bill_depth, y)
"""

X_test['mass'] = X_test['mass'].fillna(X_test['mass'].mean())

X_train.columns

X_test.isna().sum()

"""PPS = (F1_model - F1_naive) / (1 - F1_naive)"""

forest = RandomForestClassifier()
forest.fit(X_train, y_train)
train_predictions = forest.predict(X_train)
predictions = forest.predict(X_test)

train_acc = accuracy_score(y_train, train_predictions)
test_acc = accuracy_score(y_test, predictions)

train_acc, test_acc

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()



y_train = pd.Series(
    le.fit_transform(y_train),
    index=y_train.index
)

y_test = pd.Series(
    le.transform(y_test),
    index=y_test.index
)

le.classes_

y_train.head()

clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)
models,predictions = clf.fit(X_train, X_test, y_train, y_test)
print( models )

#help(LazyClassifier)

