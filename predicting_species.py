# -*- coding: utf-8 -*-
"""predicting_species.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wvK_mVjX3a0ILDre6DMfnCjBtuTB7Y-G

Problem Statement:

Scientists have determined that a known species of bird should be divided into 3 distinct and separate species. These species are endemic to a particular region of the country and their populations must be tracked and estimated with as much precision as possible. As such, a non-profit conservation society has taken up the task. They need to be able to log which species they have encountered based on the characteristics that their field officers observe in the wild.

Using certain genetic traits and location data, can you predict the species of bird that has been observed?

This is a beginner-level practice competition and your goal is to predict the bird species (A, B, or C) based on attributes or location.

## Import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd

# plotting
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
matplotlib.rcParams['figure.dpi'] = 100
sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.set(style="whitegrid")
# %matplotlib inline

# ml
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score
from sklearn.preprocessing import OneHotEncoder
import numpy as np
import ppscore as pps
from lazypredict.Supervised import LazyClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import GradientBoostingClassifier

"""## Load data"""

train = pd.read_csv("training_set.csv")
labels = pd.read_csv("training_target.csv")

# join target variable to training set
train = train.merge(labels, on="ID")

test = pd.read_csv("test_set.csv")

train.head()

train.info()

train.isna().sum().sort_values(ascending = False)

train.shape

train.shape[0]

train.isna().sum().sort_values(ascending = False).div(train.shape[0]).round(2)

for c in train.columns :
    print(f'Wartości kolumny {c}', '\n' * 2, train[c].sample(n = 10), '\n' )

train[ train.duplicated() ]

train.duplicated().sum()

print("Przed usunięciem duplikatów mamy {} wierszy".format(train.shape[0]))

train = train[ ~ train.duplicated() ]

print("Po usunięciu duplikatów mamy {} wierszy".format(train.shape[0]))

statystyki = train.describe().round(2)
statystyki.head(2)

statystyki.loc[ ['mean', '50%', 'min', 'max'], 'bill_depth' : 'sex'  ]

train.species.value_counts(normalize = True, dropna = False).plot.bar()
plt.title('Rozkład zmiennej objaśnianej (y) - gatunku ptaka')
plt.ylabel('Odsetek')
plt.xlabel('Gatunek')
plt.show()

train.location.unique()

train.head(2)

train.ID.nunique() == train.shape[0]

train = train.set_index('ID')
train.head(2)

435*0.7

y = train['species']
X = train.drop('species', axis = 1)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)

X_train.head()

X_train.isna().sum().sort_values(ascending = False).div(X_train.shape[0]).round(2)

trainset = pd.concat( [ X_train, y_train ], axis = 1 )
testset = pd.concat( [ X_test, y_test ], axis = 1 )

trainset.head()

sns.kdeplot(x = 'bill_depth', data = trainset, hue = 'species', common_norm = False)
plt.title('Rozkład głębokości dzioba dla poszczególnych gatunków')
plt.xlabel('Głębokość dzioba')
plt.show()



trainset['bill_length'].isna()

bill_length_jest = trainset [ ~ trainset['bill_length'].isna() ]
bill_length_jest.head()

bill_length_nie_ma = trainset [ trainset['bill_length'].isna() ]
bill_length_nie_ma.head()

trainset[ 'bill_length_nan'  ] = trainset['bill_length'].isna().astype(int)
trainset.head(3)

testset[ 'bill_length_nan'  ] = testset['bill_length'].isna().astype(int)

trainset.groupby('bill_length_nan')['species'].value_counts(normalize = True).unstack().plot.bar()
plt.title('Rozkład gatunku w zależności czy długość dzioba jest NaN')
plt.xlabel('Czy jest NaN?')
plt.ylabel('Odsetek ptaków')
plt.show()

encoder = SimpleImputer() # domyslnie uzywa sredniej
cols_avg = ['bill_length', 'wing_length']
trainset[cols_avg] = encoder.fit_transform(trainset[cols_avg])

testset[cols_avg] = encoder.transform(testset[cols_avg])

trainset.isna().sum().sort_values(ascending = False)

trainset.shape

one_hot = OneHotEncoder(sparse = False)
trainset['location'] = one_hot.fit_transform(pd.DataFrame(trainset['location']).values.reshape(-1, 1))
testset['location'] = one_hot.transform(pd.DataFrame(testset['location']).values.reshape(-1, 1))

trainset.shape

trainset.head(2)

trainset.isna().sum().sort_values(ascending = False) # zniknely braki po zastosowaniu OHE

trainset.location.unique() # gdzie trzecia lokacja?

ohe_test = OneHotEncoder(sparse = False)
ohe_test.fit_transform( np.array( ['a', 'b', 'c'] ).reshape(-1, 1) )

encoder = SimpleImputer(strategy = 'most_frequent')
cols_mode = ['sex']
trainset[cols_mode] = encoder.fit_transform(trainset[cols_mode])

testset[cols_mode] = encoder.transform(testset[cols_mode])

trainset.isna().sum().sum()

trainset['location'].head()

trainset.head(2)

x = 3
y = 5

print(x, y)

x, y = 7, 8

print(x, y)

X_train, y_train = trainset.drop('species', axis = 1), trainset['species']
X_test, y_test = testset.drop('species', axis = 1), testset['species']

X_test.isna().sum()

X_test['bill_depth'] = X_test['bill_depth'].fillna(X_test['bill_depth'].mean())

X_train.head()

pps.predictors(trainset, y = 'species')

pps.matrix(trainset)

"""dt = DecisionTreeClassifier()
dt.fit(bill_length, y)

dt = DecisionTreeClassifier()
dt.fit(bill_depth, y)
"""

X_test['mass'] = X_test['mass'].fillna(X_test['mass'].mean())

X_train.columns

X_test.isna().sum()

"""PPS = (F1_model - F1_naive) / (1 - F1_naive)"""

boost = GradientBoostingClassifier(learning_rate = 0.05)
boost.fit(X_train, y_train)
train_predictions = boost.predict(X_train)
predictions = boost.predict(X_test)

train_acc = accuracy_score(y_train, train_predictions)
test_acc = accuracy_score(y_test, predictions)

print( "Accuracy na zbiorze treningowym wynosi {} a na testowym {}".format(train_acc, test_acc))

from datetime import datetime
# Get current date and time
now = datetime.now()
# Format using strftime
formatted_date = now.strftime('%Y-%m-%d %H-%M-%S')
print(formatted_date) # Output: 2023-03-10 15:45:30

X_train.head(2)

pd.Series( X_train.columns.tolist() ).to_csv('kolumny oczekiwane przez gradient_boost_created_{}'.format(formatted_date))

import joblib



joblib.dump(boost, 'gradient_boost_created_{}.joblib'.format(formatted_date))

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()



y_train = pd.Series(
    le.fit_transform(y_train),
    index=y_train.index
)

y_test = pd.Series(
    le.transform(y_test),
    index=y_test.index
)

le.classes_

y_train.head()

clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)
models,predictions = clf.fit(X_train, X_test, y_train, y_test)
models

"""## Znajdowanie parametrów modelu w kroskwalidacji"""

kwadraty_liczb = { i : i ** 2 for i in range(4) }
kwadraty_liczb

param_distributions = {'min_samples_leaf' : [10, 15, 20 ],
                       'min_samples_split' : [10, 15, 20 ],
                       'max_depth' : [1, 2, 3, 4  ] }



grid = RandomizedSearchCV(boost, param_distributions, n_iter = 30)
grid.fit(X_train, y_train)

grid.best_estimator_

#grid.cv_results_

cv_acc = round ( grid.best_score_ , 3)

nowy_model = grid.best_estimator_
new_train_preds = nowy_model.predict(X_train)
new_preds = nowy_model.predict(X_test)


new_train_acc = round ( accuracy_score(y_train, new_train_preds), 4 )
new_test_acc = round(  accuracy_score(y_test, new_preds), 4 )

print( "Accuracy na zbiorze treningowym wynosi {} a na testowym {}. Accuracy w kroswalidacji {}".format(new_train_acc, new_test_acc, cv_acc))

print(classification_report(y_test, new_preds))

#help(forest)

#help(LazyClassifier)
help(RandomizedSearchCV)

